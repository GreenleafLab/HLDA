#!/usr/bin/env Rscript

##########################################################################
# Score and summarize results from gkmexplain
##########################################################################

#Load ArchR (and associated libraries)
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(data.table)
  library(stringr)
  library(Biostrings)
  library(BSgenome.Hsapiens.UCSC.hg38)
  library(parallel)
})

# Set Threads to be used
ncores <- 12

# Get additional functions, etc.:
scriptPath <- "/oak/stanford/groups/wjg/skim/projects/LDA/scripts"
source(paste0(scriptPath, "/misc_helpers.R"))
source(paste0(scriptPath, "/matrix_helpers.R"))
source(paste0(scriptPath, "/plotting_config.R"))

# gkmexplain results directory
gkm_exp_dir <- "/oak/stanford/groups/wjg/skim/projects/LDA/GWAS/gkmSVM/snp_explanations"

#Set/Create Working Directory to Folder
gkm_res_dir <- "/oak/stanford/groups/wjg/skim/projects/LDA/GWAS/gkmSVM/snp_results"
dir.create(gkm_res_dir, showWarnings = FALSE, recursive = TRUE)
setwd(gkm_res_dir)

# Read in origianl SNP genomic range
snp_gr <- readRDS("/oak/stanford/groups/wjg/skim/projects/LDA/GWAS/gkmSVM/snp_fastas/250bpSNPCentered.rds")

# Load parsed gkmexplain results
snp_gkmexplain <- readRDS(file=paste0(gkm_res_dir, "/snp_gkmexplain_results.rds"))

# plot directory
plotDir <- "/oak/stanford/groups/wjg/skim/projects/LDA/2_chrombpnet/plots"

##########################################################################################
# Parse chrombpnet variant scorer outputs
##########################################################################################

variant_scorer_dir <- "/oak/stanford/groups/wjg/skim/projects/LDA/2_chrombpnet/snp_effect_prediction/variant_scorer/outputs_averaged"

variant_scorer_files <- list.files(
  path=variant_scorer_dir, 
  pattern="\\.mean\\.variant_scores\\.tsv$", 
  full.names=TRUE
  )

ct_names <- stringr::str_extract(basename(variant_scorer_files),"[^.]+")

snp_variantscorer <- lapply(variant_scorer_files, function(file){
  df <- readr::read_tsv(file) %>% as.data.frame()
  df$rsID <- sub(".*?,\\s*", "", df$variant_id)
  df
  }) 
names(snp_variantscorer) <- ct_names

# Test
tmp.df <- dplyr::full_join(snp_variantscorer$TiP1, snp_gkmexplain$score_summaries$TiP1, by = c("rsID" = "snp"))
tmp.df$abs_score_delta <- abs(tmp.df$score_delta)

tmp.df$corrected.logfc.mean <- -tmp.df$logfc.mean
result=cor.test(tmp.df$corrected.logfc.mean, tmp.df$score_delta, method = "spearman")
print(result)

library(ggpubr)
pdf(paste0(plotDir, "/temp.plot.pdf"))
ggscatter(tmp.df, x = "corrected.logfc.mean", y = "score_delta", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "spearman",
          xlab = "logfc.mean_cbpnet", ylab = "score_delta_gkmexplain")
ggqqplot(tmp.df$corrected.logfc.mean, ylab = "logfc.mean.cbpnet")
ggqqplot(tmp.df$score_delta, ylab = "score_delta_gkmexplain")
dev.off()
##########################################################################################
# Functions
##########################################################################################

read_gkmexplain_res <- function(gkm_exp_files, expected_length=251){
  # Read in all gkmexplain result files and combine into a single data.table
  # gkmexplain outputs files with 3 columns:
  # column 1: sequence name (from original fasta file)
  # column 2: predicted score (gkmpredict)
  # column 3: the gkmexplain "explanation"
  #
  # "explanation" is stored in a format consisting of sets of four values separated by semilcolons. 
  # Each group corresponds to a position in the original input sequence. The four values within a 
  # group correspond to the bases ACGT. If using the explanation mode of 0 (i.e. "importance scores"), 
  # all but one of the bases will have a score of 0; the base with a nonzero score corresponds to the 
  # base that was present in the original input sequence. Hypothetical importance scores (generated by modes 1 and 2) 
  # produce estimates of what the importance score would be if a different base were present in the underlying sequence; 
  # when looking at hypothetical importance scores, multiple bases at a given position will likely have nonzero scores.
  #
  # This function will return the non-zero scores from the 3rd column, and assumes that there is only one non-zero score
  # (i.e. do not use this function if you are computing 'Hypothetical' importance scores)

  full_dt <- rbindlist(lapply(gkm_exp_files, function(x) fread(x, sep="\t")))
  explanation <- full_dt[[3]]

  # Parse the full gkmexplain score report
  explanation_matrices <- lapply(explanation, function(x){
    score_mat <- strsplit(x,";",fixed=TRUE) %>% unlist() %>% strsplit(.,",",fixed=TRUE) %>% unlist() %>% as.numeric() %>% matrix(.,nrow=4)
    rownames(score_mat) <- c("A", "C", "G", "T")
    colnames(score_mat) <- paste0("P", 1:ncol(score_mat))
    #########
    # Check if there is something going wrong with some explanation results
    if(ncol(score_mat) != expected_length){
      message("Error! This SNP does not have the correct number of columns?")
      print(x)
    }
    #########
    return(score_mat)
    })
  names(explanation_matrices) <- full_dt[[1]]

  # Also return a single matrix of 'flattened' scores per sequence
  explanation <- sapply(explanation_matrices, function(x) colSums(x)) %>% t()

  list(seq_names=full_dt[[1]], gkm_score=full_dt[[2]], explanations=explanation, seq_matrices=explanation_matrices)
}


parse_full_gkmexplain_output <- function(meta_df, ncores=8, window_size=50){
  # Parse all files listed in the provided dataframe and perform initial score summarizing
  # Initial score summarizing steps:
  # 1) Read in files after grouping by model type (cluster) and target class (e.g. ref_snp_seqs)
  # 2) Compute sum of importance scores for central 50bp of each sequence
  # 3) Calculate differences between ref and alt alleles for matched sequences
  # 
  # This will return a list of multiple objects
  # 1 - list of gkmexplain output for each initial grouping (e.g. Tc-ref_snp_seqs), which itself is a list of 
  #   the sequence name, the full gkmpredict score, and the per-base importance scores for the central 300bp of the region
  # 2 - list of score summary dfs by model type, which contains the region, the snp, the score for ref and alt alleles, and the
  #   score delta
  message("Parsing gkmexplain output...")
  group_files <- meta_df %>% group_by(cluster, snp_type) %>% group_map(~ .x$exp_file)
  names(group_files) <- meta_df %>% group_by(cluster, snp_type) %>% group_keys() %>% unite(col="names", sep="-") %>% pull(names)
  ##########################################################################################
  if(ncores > 1){
    # Perform parsing steps in parallel
    res_list <- mclapply(names(group_files), function(grp){
      message(sprintf("Parsing gkmexplain output for %s...",grp))
      read_gkmexplain_res(group_files[[grp]])
      }, mc.cores=ncores)
  }else{
    # Perform parsing steps in parallel
    res_list <- lapply(names(group_files), function(grp){
      message(sprintf("Parsing gkmexplain output for %s...",grp))
      read_gkmexplain_res(group_files[[grp]])
      })
  }
  names(res_list) <- names(group_files)
  ##########################################################################################
  message("Computing summary scores for central region of sequence...")
  # Now compute the sum of importance scores for the sequence surrounding the SNP
  half_window <- floor(window_size/2)
  
  score_df_list <- list()
  for(grp in names(res_list)){
    message(sprintf("Getting summary info for %s...", grp))
    seqnames <- res_list[[grp]]$seq_names
    rel_snp_pos <- sapply(strsplit(seqnames, "_"), `[`, 5) %>% as.numeric()
    # Get the full range
    full_range <- res_list[[grp]]$explanations
    max_len <- ncol(full_range)
    # Get the window containing the SNP (ensuring that intervals are within bounds)
    rel_snp_pos[rel_snp_pos <= half_window] <- half_window + 1
    rel_snp_pos[rel_snp_pos >= max_len - half_window] <- max_len - (half_window)
    intervals <- data.frame(start=rel_snp_pos - half_window, end=rel_snp_pos + half_window)
    window_range <- sapply(1:nrow(full_range), function(ix){
      full_range[ix,intervals[ix,1]:intervals[ix,2]]
      }) %>% t()
    # Store df of score information
    df <- data.frame(seq_names=seqnames, full_score=full_range %>% rowSums(), window_score=window_range %>% rowSums())
    score_df_list[[grp]] <- df
  }
  message("Creating final dataframe of score summaries...")
  # Combine dataframes by model type
  clusters <- unique(meta_df$cluster)
  cell_types <- unique(clusters)

  final_score_df_list <- lapply(cell_types, function(ct){
    ref_df <- score_df_list[[paste0(ct, "-ref_snp_seqs")]]
    ref_seqnames <- ref_df$seq_names
    alt_df <- score_df_list[[paste0(ct, "-alt_snp_seqs")]]
    alt_seqnames <- alt_df$seq_names
    region <- sapply(strsplit(ref_seqnames, "_"), function(x) paste(head(x, 3), collapse="_"))
    snp <- sapply(strsplit(ref_seqnames, "_"), `[`, 4)
    df <- data.frame(
      region=region, snp=snp,
      ref_full=ref_df$full_score, alt_full=alt_df$full_score, 
      ref_window=ref_df$window_score, alt_window=alt_df$window_score)
    df$score_delta <- df$ref_window - df$alt_window
    #df$active_allele <- ifelse(df$score_delta > 0, "ref", "alt")
    return(df)
    })

  names(final_score_df_list) <- cell_types

  return(
    list(
      "gkmexplain_output"=res_list,
      "score_summaries"=final_score_df_list
      )
    )
}

##########################################################################################
# Read in native SNP predictions
##########################################################################################

snp_files <- list.files(
  path=gkm_exp_dir, 
  pattern="\\.250bpSNPCentered\\.chr.*\\.gkmexplain\\.txt$", 
  full.names=TRUE
  )

# Files have the format <path>/<pred_cluster>.full.<target_type>.<target_class>.chr[1-22,X].gkmexplain.txt
clusters <- str_replace(basename(snp_files), "\\.full\\..*\\.txt$", "")
snp_type <- str_match(basename(snp_files), "(alt|ref)_snp_seqs")[,1]
chroms <- str_match(basename(snp_files), "chr[0-9,X]+")[,1]

meta_df <- data.frame(cluster=clusters, snp_type=snp_type, chr=chroms, exp_file=snp_files)

#snp_gkmexplain <- parse_full_gkmexplain_output(meta_df, ncores=ncores)
snp_gkmexplain <- parse_full_gkmexplain_output(meta_df, ncores=1)

##########################################################################################
# Read in dinucleotide shuffled SNP predictions
##########################################################################################

shuff_files <- list.files(
  path=gkm_exp_dir, 
  pattern="\\.250bpSNPCentered_shuff\\.chr.*\\.gkmexplain\\.txt$", 
  full.names=TRUE
  )

# Files have the format <path>/<pred_cluster>.fold0.<target_type>.<target_class>.chr[1-22,X].gkmexplain.txt
clusters <- str_replace(basename(shuff_files), "\\.full\\..*\\.txt$", "")
snp_type <- str_match(basename(shuff_files), "(alt|ref)_snp_seqs")[,1]
chroms <- str_match(basename(shuff_files), "chr[0-9,X]+")[,1]

meta_df <- data.frame(cluster=clusters, snp_type=snp_type, chr=chroms, exp_file=shuff_files)

#shuff_gkmexplain <- parse_full_gkmexplain_output(meta_df, ncores=ncores)
shuff_gkmexplain <- parse_full_gkmexplain_output(meta_df, ncores=1)

##########################################################################################
# Save parsed gkmexplain results for faster loading
##########################################################################################

# (These are pretty huge objects: ~4GB for 16k snps...)
saveRDS(snp_gkmexplain, file=paste0(gkm_res_dir, "/snp_gkmexplain_results.rds"))
saveRDS(shuff_gkmexplain, file=paste0(gkm_res_dir, "/shuff_gkmexplain_results.rds"))


snp_gkmexplain <- readRDS(paste0(gkm_res_dir, "/snp_gkmexplain_results.rds"))
shuff_gkmexplain <- readRDS(paste0(gkm_res_dir, "/shuff_gkmexplain_results.rds"))

##########################################################################################
# Identify 'seqlets' and compute 'prominence' and 'magnitude' scores
##########################################################################################

# First, identify 97.5%-ile cutoff from shuffled sequences
cell_types <- shuff_gkmexplain$score_summaries %>% names()

cutoffs <- lapply(cell_types, function(ct){
  ref_mats <- shuff_gkmexplain$gkmexplain_output[[paste0(ct,"-ref_snp_seqs")]]$seq_matrices
  alt_mats <- shuff_gkmexplain$gkmexplain_output[[paste0(ct,"-alt_snp_seqs")]]$seq_matrices
  nonneg_scores <- sapply(1:length(ref_mats), function(ix){
    ref_mat <- ref_mats[[ix]]
    alt_mat <- alt_mats[[ix]]
    ref_mat[ref_mat < 0] <- 0
    alt_mat[alt_mat < 0] <- 0
    c(colSums(ref_mat), colSums(alt_mat))
    }) %>% c()
  quantile(nonneg_scores, 0.975)
  }) %>% unlist()
names(cutoffs) <- cell_types


# Now, compute all seqlets and associated scores

scoreProminence <- function(gkm_res, cutoffs, cell_types, mat_idx=101:151){
  # Calculate 'Prominence' and 'Magnitude' of the ref vs alt allele for a gkm_res object
  ####################################
  # gkm_res = parsed gkm_explain output (list of gkmexplain_output and score_summaries)
  # cutoffs = previously determined cutoffs for per-base gkmexplain magnitude for seqlet identification
  # mat_idx = column indices corresponding to inner window (only fixed for SNP-centered scoring)

  new_score_sums <- lapply(cell_types, function(ct){
    message(sprintf("Computing scores for %s...", ct))
    ref_mats <- gkm_res$gkmexplain_output[[paste0(ct,"-ref_snp_seqs")]]$seq_matrices
    alt_mats <- gkm_res$gkmexplain_output[[paste0(ct,"-alt_snp_seqs")]]$seq_matrices

    # Get the SNP window to use
    score_sum <- gkm_res$score_summaries[[ct]]
    #windows <- score_sum[,c("window_start", "window_end")]
    cutoff <- cutoffs[ct]

    seqlets <- lapply(1:length(ref_mats), function(ix){

      # Get inner matrix from ref and alt alleles
      ref_mat <- ref_mats[[ix]]
      alt_mat <- alt_mats[[ix]]

      # For these calculations, we care only about non-negative importance scores
      ref_mat[ref_mat < 0] <- 0
      alt_mat[alt_mat < 0] <- 0

      # Identify the 'active' allele (i.e. the one with the larger absolute effect on accessibility)
      ref_sum <- sum(colSums(ref_mat[,mat_idx]))
      alt_sum <- sum(colSums(alt_mat[,mat_idx]))

      if(ref_sum > alt_sum){
        active_mat <- ref_mat
        inactive_mat <- alt_mat
        amat_name <- "ref"
      }else{
        active_mat <- alt_mat
        inactive_mat <- ref_mat
        amat_name <- "alt"
      }

      # Identify seqlets
      acs <- colSums(active_mat[,mat_idx])
      v <- which(acs > cutoff)
      diffs <- diff(v)-1 # Get differences between consecutive indices 

      intervals <- R.utils::seqToIntervals(v)
      # Collapse intervals separated by 1 or fewer bases
      intervals <- IRanges(start=intervals[,1], end=intervals[,2]) %>% reduce(.,min.gapwidth=2)

      # Identify interval containing snp (middle of window)
      snp_pos <- ceiling(length(mat_idx)/2)
      seq_range <- intervals[intervals %over% IRanges(start=snp_pos, end=snp_pos)]
      if(length(seq_range) < 1){
        # If no interval found, then take 7 bases around SNP
        seq_range <- IRanges(start=snp_pos-3, end=snp_pos+3)
      }
      if(width(seq_range)[1] < 7){
        # If interval is less than 7 bases, extend to be 7 bases
        seq_range <- resize(seq_range, width=7, fix='center')
      }
      start_ix <- start(seq_range)
      end_ix <- end(seq_range)
      names(start_ix) <- names(acs)[start_ix]
      names(end_ix) <- names(acs)[end_ix]

      ## Calculate 'prominence' and 'magnitude' scores
      # First, get seqlet scores for 'active' and 'inactive' matrices
      mat_names <- colnames(active_mat)
      seqlet_ix <- which(mat_names == names(start_ix)):which(mat_names == names(end_ix))
      seqlet_amat <- active_mat[,seqlet_ix] 
      seqlet_imat <- inactive_mat[,seqlet_ix]
      # Compute 'effect/non-effect signal to noise ratio'
      aseqscore <- sum(colSums(seqlet_amat))
      asnr <- aseqscore/sum(colSums(active_mat))
      iseqscore <- sum(colSums(seqlet_imat))
      isnr <- iseqscore/sum(colSums(inactive_mat))
      # Compute prominence and magnitude (cannot be negative)
      prominence <- max(asnr - isnr, 0)
      magnitude <- max(aseqscore - iseqscore, 0)
      data.frame(seqlet_start=names(start_ix), seqlet_end=names(end_ix), seqlet_width=end_ix-start_ix+1, 
        prominence=prominence, magnitude=magnitude, active_allele=amat_name)
      }) %>% do.call(rbind,.)

    # Add seqlet info to summary
    new_score_sum <- cbind(gkm_res$score_summaries[[ct]], seqlets)
    #rownames(new_score_sum) <- paste0(new_score_sum$snp, "_", ct)
    rownames(new_score_sum) <- 1:nrow(new_score_sum)
    new_score_sum
  })
  names(new_score_sums) <- cell_types

  message("Adding updated score summaries to gkm_res...")
  for(ct in cell_types){
    gkm_res$score_summaries[[ct]] <- new_score_sums[[ct]]
  }
  return(gkm_res)
}


# SNP gkmexplain first:
snp_gkmexplain <- scoreProminence(snp_gkmexplain, cutoffs=cutoffs, cell_types=names(cutoffs))

# Compute for 'null' sequences as well:
shuff_gkmexplain <- scoreProminence(shuff_gkmexplain, cutoffs=cutoffs, cell_types=names(cutoffs))

saveRDS(snp_gkmexplain, file=paste0(gkm_res_dir, "/snp_gkmexplain_results.rds"))
saveRDS(shuff_gkmexplain, file=paste0(gkm_res_dir, "/shuff_gkmexplain_results.rds"))

##########################################################################################

library(ggplot2)

trait_groups <- list(
  asthma=c("Asthma (childhood onset)", "Asthma", "Asthma (adult onset)", "Childhood asthma with severe exacerbations"),
#  cysticfibrosis=c("Lung disease severity in cystic fibrosis"),
  spirometry=c("Lung function (FVC)", "FEV1", "Lung function (FEV1/FVC)", "FEV1FVC"),
  random=c("random")
  )

snp_groups <- lapply(trait_groups, function(grp) snp_gr$linked_SNP[snp_gr$disease_trait %in% grp])

trait_colors <- c(
  asthma="orange",
  #cysticfibrosis="blue",
  spirometry="green4", # green
  random="grey60"
  )

##########################################################################################
# Estimate null distributions with a parameterized distribution
##########################################################################################

library(metRology)
library(fitdistrplus)

# Calculate null distribution for each cell type
shuff_delta_mat <- lapply(shuff_gkmexplain$score_summaries, function(x) x$score_delta) %>% do.call(cbind,.) 

# Fit distributions for score delta
normal_dist_params <- apply(shuff_delta_mat, 2, function(x) fitdistrplus::fitdist(x, distr="norm"))
t_dist_params <- apply(shuff_delta_mat, 2, function(x) fitdistrplus::fitdist(x, distr="t.scaled", start=list(df=6, mean=mean(x), sd=sd(x))))

pdf(paste0(gkm_res_dir, "/qq_normal.pdf"), width=5, height=5)
lapply(names(normal_dist_params), function(nm) fitdistrplus::qqcomp(list(normal_dist_params[[nm]]), main=nm))
dev.off()

pdf(paste0(gkm_res_dir, "/qq_tscaled.pdf"), width=5, height=5)
lapply(names(t_dist_params), function(nm) fitdistrplus::qqcomp(list(t_dist_params[[nm]]), main=nm))
dev.off()

# Fit distributions for prominence
shuff_prom_mat <- lapply(shuff_gkmexplain$score_summaries, function(x) x$prominence) %>% do.call(cbind,.) 

pdf(paste0(gkm_res_dir, "/prom_hist.pdf"), width=5, height=5)
lapply(colnames(shuff_prom_mat), function(nm) hist(shuff_prom_mat[,nm], breaks=50, main=nm))
dev.off()

exp_params <- apply(shuff_prom_mat, 2, function(x) fitdistrplus::fitdist(x, distr="exp"))
pdf(paste0(gkm_res_dir, "/prom_exp_qq.pdf"), width=5, height=5)
lapply(names(exp_params), function(nm) fitdistrplus::qqcomp(list(exp_params[[nm]]), main=nm))
dev.off()

##########################################################################################
# Calculate p-values for each snp in each cell type using fit null distributions
##########################################################################################

sd_pval_res <- list()
pr_pval_res <- list()

for(ct in cell_types){

  # Score delta p-values
  sd_params <- t_dist_params[[ct]]$estimate
  score_deltas <- snp_gkmexplain$score_summaries[[ct]]$score_delta
  pvals <- 2*metRology::pt.scaled(-abs(score_deltas - sd_params["mean"]), 
    df=sd_params["df"], mean=0, sd=sd_params["sd"])
  snp_gkmexplain$score_summaries[[ct]]$sd_pval <- pvals
  sd_pval_res[[ct]] <- pvals

  # Prominence p-values
  prom_params <- exp_params[[ct]]$estimate
  prominences <- snp_gkmexplain$score_summaries[[ct]]$prominence
  pvals <- pexp(prominences, rate=prom_params["rate"], lower.tail=FALSE)
  snp_gkmexplain$score_summaries[[ct]]$pr_pval <- pvals
  pr_pval_res[[ct]] <- pvals
}

##########################################################################################
# Examine enrichment of high-effect hits
##########################################################################################

# p-value cutoffs for significant hits
significant_hits <- lapply(cell_types, function(ct){
  score_sum <- snp_gkmexplain$score_summaries[[ct]]
  score_sum <- score_sum[((score_sum$sd_pval < 0.05) & (score_sum$pr_pval < 0.05)),]
  score_sum$cluster <- ct
  score_sum
  }) %>% do.call(rbind,.)

# Add finemapping prior probability to significant hits
trait_to_traitgrp <- invertList(trait_groups) %>% unlist()
fm_probs <- snp_gr$fm_prob
names(fm_probs) <- snp_gr$linked_SNP
traits <- trait_to_traitgrp[snp_gr$disease_trait]
names(traits) <- snp_gr$linked_SNP

significant_hits$fm_probs <- round(fm_probs[significant_hits$snp], 4)
significant_hits$trait <- factor(traits[significant_hits$snp])

# Get order of traits and 
trait_order <- names(trait_groups)
snp_totals <- unlist(lapply(snp_groups[names(trait_groups)], length))

# Look at number of significant hits by cell type for each trait
nsig <- lapply(cell_types, function(ct){
  ct_sig <- significant_hits[significant_hits$cluster == ct,]
  frq <- ct_sig$trait %>% getFreqs()
  frq[trait_order]
  }) %>% do.call(rbind,.)
rownames(nsig) <- cell_types
colnames(nsig) <- trait_order

# Compute fisher p-values and odds ratios
fisherTestSig <- function(nsigvec1, ntotal1, nsigvec2, ntotal2){
  df <- data.frame(nsigvec1, nsigvec2)
  res_df <- apply(df, 1, function(x){
    x1sig <- x[1]
    x2sig <- x[2]
    x1nsig <- ntotal1 - x1sig
    x2nsig <- ntotal2 - x2sig
    OR <- (x1sig/x1nsig)/(x2sig/x2nsig)
    pval <- fisher.test(matrix(c(x1sig, x1nsig, x2sig, x2nsig), 2, 2), alternative="greater")$p.value
    data.frame(OR=OR, pval=pval)
    }) %>% do.call(rbind,.)
  res_df
}

# Calculate odds ratio and p-value for each cluster (model)
sig_enrichment <- lapply(names(snp_totals), function(sg){
  df <- fisherTestSig(nsig[,sg], snp_totals[sg], nsig[,"random"], snp_totals["random"])
  df$trait <- sg
  df$cluster <- rownames(df)
  df
  }) %>% do.call(rbind,.)

OR_sig <- unmelt(sig_enrichment[sig_enrichment$trait != "random",], 
  row_col="cluster", col_col="trait", val_col="OR") %>% as.data.frame()

pct_sig <- t(t(nsig)/snp_totals) * 100

# Plot OR by cluster on full UMAP
library(ArchR)
source(paste0(scriptPath, "/archr_helpers.R"))
atac_proj <- loadArchRProject("/oak/stanford/groups/wjg/skim/projects/LDA/1b_atac_preprocess/lda")

# Plot scATAC with ATAC cluster labels
umapPlots <- list()
umapDF <- buildUMAPdfFromArchR(atac_proj, cellColData="FineNamedClust", embeddingName = "customUMAP")
or_lims <- c(-0.5, 0.5)

for(trait in colnames(OR_sig)){
  clust_to_OR <- OR_sig[,trait]
  names(clust_to_OR) <- rownames(OR_sig)
  plotDF <- umapDF
  plotDF$FineNamedClust <- log2(clust_to_OR[plotDF$FineNamedClust])
  plotDF$FineNamedClust[plotDF$FineNamedClust < or_lims[1]] <- or_lims[1]
  plotDF$FineNamedClust[plotDF$FineNamedClust > or_lims[2]] <- or_lims[2]
  umapPlots[[trait]] <- plotUMAP(plotDF, dataType = "quantitative", cmap=cmaps_BOR$brewer_yes, 
    colorLims=or_lims, point_size=0.4, na.value="white", # gray35 by default
    covarLabel=sprintf("log2 OR %s", trait), useRaster=TRUE)
}

pdf(paste0(gkm_res_dir,"/hit_enrichments_UMAP.pdf"), width=10, height=8)
umapPlots
dev.off()

# Subset to hits that we actually care about
significant_hits <- significant_hits[significant_hits$snp %in% c(snp_groups[["asthma"]], snp_groups[["spirometry"]], snp_groups[["cysticfibrosis"]]),]

# Get all seqlets
significant_hits$seqlet_seq <- apply(significant_hits, 1, function(x){
  snp <- x[2]
  start <- as.numeric(sub(".", "", x[8]))
  end <- as.numeric(sub(".", "", x[9]))
  full_seq <- mcols(snp_gr[snp_gr$linked_SNP == snp])[1,paste0(x[13],"seq")]
  subseq <- subseq(full_seq, start=start, end=end) %>% as.character()
  subseq
  }) %>% unname()

#Save necessary files to run the motif matching locally
saveRDS(significant_hits, paste0(gkm_res_dir, "/significant_hits.rds"))
saveRDS(snp_gkmexplain, paste0(gkm_res_dir, "/snp_gkmexplain.rds"))

significant_hits <- readRDS(paste0(gkm_res_dir, "/significant_hits.rds"))
snp_gkmexplain <- readRDS(paste0(gkm_res_dir, "/snp_gkmexplain.rds"))

##########################################################################################
# Use tomtom to identify likely motif matches for each seqlet
##########################################################################################

getBestMotifMatchesTemp <- function(snp, snp_table, gkm_explain_output, celltype, 
  qvalcutoff=0.1, maxN=8, meme_temp_dir=paste0(gkm_res_dir, "/meme_temp")){
  # Use MEME's tomtom to identify the best matching motifs for a provided SNP

  # Get required names for accessing data
  snp_info <- snp_table[(snp_table$snp == snp & snp_table$cluster == celltype),]
  ref_group <- paste0(celltype, "-ref_snp_seqs")
  alt_group <- paste0(celltype, "-alt_snp_seqs")
  snp_region <- paste0(snp_info$region, "_", snp, "_125")
  seqlet <- snp_info$seqlet_seq
  
  # Get seqlet region
  if(snp_info$active_allele == "ref"){
    active_grp <- ref_group
    inactive_grp <- alt_group
  }else{
    active_grp <- alt_group
    inactive_grp <- ref_group
  }

  # Retrieve importance scores spanning seqlet
  seqlet_start <- as.numeric(sub(".", "", snp_info$seqlet_start)) 
  seqlet_end <- as.numeric(sub(".", "", snp_info$seqlet_end))
  active_mat <- gkm_explain_output$gkmexplain_output[[active_grp]]$seq_matrices[[snp_region]][,seqlet_start:seqlet_end]
  inactive_mat <- gkm_explain_output$gkmexplain_output[[inactive_grp]]$seq_matrices[[snp_region]][,seqlet_start:seqlet_end]

  # Threshold to zero and get delta matrix
  active_mat[active_mat < 0] <- 0
  inactive_mat[inactive_mat < 0] <- 0
  delta_mat <- active_mat - inactive_mat

  return(delta_mat)
  
  # Zero values cause issues with the ICM format
  #delta_mat[delta_mat <= 0] <- 0.0001
  
  # Normalize to maximum signal
  #delta_mat <- delta_mat/max(delta_mat)

  # # Create Information Content Motif (multiply by 2 to have 2 bits for maximum value position)
  # # (Need to remove row and column names from matrix for create_motif to allow 'DNA' alphabet)
  # motif <- universalmotif::create_motif(
  #   unname(delta_mat)*2, 
  #   alphabet="DNA", type="ICM"
  #   ) 
  
  # # Run TomTom
  # # (Setting incomplete scores to 'TRUE' causes tomtom to compute scores using only aligned bases.
  # # This will avoid longer motifs being penalized compared to shorter motifs)
  # ttres <- memes::runTomTom(motif, outdir=meme_temp_dir, incomplete_scores=TRUE)

  # # Return NA data.frame if no matches are found (tomtom df will be 'NA')
  # if(class(ttres$tomtom[[1]]) != "logical"){
  #   tom_df <- ttres$tomtom[[1]]
  # }else{
  #   message(sprintf("No matches found for sequence %s. Exiting",seqlet))
  #   return(NA)
  # }
  # # Return string of top motifs, with * to indicate those that are significant
  # qvals <- tom_df$match_qval %>% head(maxN)
  # matches <- tom_df$match_altname %>% head(maxN)
  # matches <- ifelse(qvals < 0.1, paste0(matches,"*"), matches)
  # matches <- ifelse(qvals < 0.01, paste0(matches,"*"), matches)
  # matches <- ifelse(qvals < 0.001, paste0(matches,"*"), matches)
  # paste0(matches,collapse=";")
}

# Get all predicted motifs
start_time <- Sys.time()

delta_mat_list <- list()
delta_mat_list <- sapply(1:nrow(significant_hits), function(ix){
  getBestMotifMatchesTemp(
    snp=significant_hits[ix,"snp"],
    snp_table=significant_hits,
    gkm_explain_output=snp_gkmexplain,
    celltype=significant_hits[ix,"cluster"]
    )
  })

# Saving the delta_mat_list to run locally the rest of the motif calling
saveRDS(delta_mat_list, paste0(gkm_res_dir, "/delta_mat_list.rds"))

#####################################################
# Below could not be run due to R 4.0.2
# Switch to SCG with R set to 4.2.2 but cannot run without libevent but not present in module load
# Run locally

library(memes)
library(universalmotif)
options(meme_bin = "/oak/stanford/groups/wjg/skim/software/meme-5.4.1/bin")
options(meme_db = "/oak/stanford/groups/wjg/skim/projects/LDA/resources/meme_motifs/motif_databases/CIS-BP_2.00/Homo_sapiens.meme")


getBestMotifMatches <- function(snp, snp_table, gkm_explain_output, celltype, 
  qvalcutoff=0.1, maxN=8, meme_temp_dir=paste0(gkm_res_dir, "/meme_temp")){
  # Use MEME's tomtom to identify the best matching motifs for a provided SNP

  # Get required names for accessing data
  snp_info <- snp_table[(snp_table$snp == snp & snp_table$cluster == celltype),]
  ref_group <- paste0(celltype, "-ref_snp_seqs")
  alt_group <- paste0(celltype, "-alt_snp_seqs")
  snp_region <- paste0(snp_info$region, "_", snp, "_125")
  seqlet <- snp_info$seqlet_seq
  
  # Get seqlet region
  if(snp_info$active_allele == "ref"){
    active_grp <- ref_group
    inactive_grp <- alt_group
  }else{
    active_grp <- alt_group
    inactive_grp <- ref_group
  }

  # Retrieve importance scores spanning seqlet
  seqlet_start <- as.numeric(sub(".", "", snp_info$seqlet_start)) 
  seqlet_end <- as.numeric(sub(".", "", snp_info$seqlet_end))
  active_mat <- gkm_explain_output$gkmexplain_output[[active_grp]]$seq_matrices[[snp_region]][,seqlet_start:seqlet_end]
  inactive_mat <- gkm_explain_output$gkmexplain_output[[inactive_grp]]$seq_matrices[[snp_region]][,seqlet_start:seqlet_end]

  # Threshold to zero and get delta matrix
  active_mat[active_mat < 0] <- 0
  inactive_mat[inactive_mat < 0] <- 0
  delta_mat <- active_mat - inactive_mat

  # Zero values cause issues with the ICM format
  delta_mat[delta_mat <= 0] <- 0.0001
  
  # Normalize to maximum signal
  delta_mat <- delta_mat/max(delta_mat)

  # Create Information Content Motif (multiply by 2 to have 2 bits for maximum value position)
  # (Need to remove row and column names from matrix for create_motif to allow 'DNA' alphabet)
  motif <- universalmotif::create_motif(
    unname(delta_mat)*2, 
    alphabet="DNA", type="ICM"
    ) 
  
  # Run TomTom
  # (Setting incomplete scores to 'TRUE' causes tomtom to compute scores using only aligned bases.
  # This will avoid longer motifs being penalized compared to shorter motifs)
  ttres <- memes::runTomTom(motif, outdir=meme_temp_dir, incomplete_scores=TRUE)

  # Return NA data.frame if no matches are found (tomtom df will be 'NA')
  if(class(ttres$tomtom[[1]]) != "logical"){
    tom_df <- ttres$tomtom[[1]]
  }else{
    message(sprintf("No matches found for sequence %s. Exiting",seqlet))
    return(NA)
  }
  # Return string of top motifs, with * to indicate those that are significant
  qvals <- tom_df$match_qval %>% head(maxN)
  matches <- tom_df$match_altname %>% head(maxN)
  matches <- ifelse(qvals < 0.1, paste0(matches,"*"), matches)
  matches <- ifelse(qvals < 0.01, paste0(matches,"*"), matches)
  matches <- ifelse(qvals < 0.001, paste0(matches,"*"), matches)
  paste0(matches,collapse=";")
}

significant_hits$top_motifs <- sapply(1:nrow(significant_hits), function(ix){
  getBestMotifMatches(
    snp=significant_hits[ix,"snp"],
    snp_table=significant_hits,
    gkm_explain_output=snp_gkmexplain,
    celltype=significant_hits[ix,"cluster"]
    )
  })
end_time <- Sys.time()
message(sprintf("Found motifs in %s minutes", round(difftime(end_time, start_time, units="mins"), 2)))

# Save intermediate results
saveRDS(significant_hits, file=paste0(gkm_res_dir, "/significant_hits_table.rds"))
saveRDS(snp_gkmexplain, file=paste0(gkm_res_dir, "/snp_gkmexplain_results.rds"))
saveRDS(shuff_gkmexplain, file=paste0(gkm_res_dir, "/shuff_gkmexplain_results.rds"))

##########################################################################################

